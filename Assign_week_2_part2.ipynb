{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "844d1ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import turicreate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e570a85f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/arkojit/ML Regression/kc_house_data.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/arkojit/ML Regression/kc_house_data.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.440995 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.440995 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[int,str,float,int,float,int,int,float,int,int,int,int,int,int,int,int,int,float,float,int,int]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/arkojit/ML Regression/kc_house_data.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/arkojit/ML Regression/kc_house_data.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 21613 lines in 0.287296 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 21613 lines in 0.287296 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sales = turicreate.SFrame('kc_house_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96ce042e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af3b1c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_numpy_data(data_sframe, features, output):\n",
    "    data_sframe['constant'] = 1 # this is how you add a constant column to an SFrame\n",
    "    # add the column 'constant' to the front of the features list so that we can extract it along with the others:\n",
    "    features = ['constant'] + features # this is how you combine two lists\n",
    "    # select the columns of data_SFrame given by the features list into the SFrame features_sframe (now including constant):\n",
    "    features_sframe=data_sframe[features]\n",
    "    # the following line will convert the features_SFrame into a numpy matrix:\n",
    "    feature_matrix = features_sframe.to_numpy()\n",
    "    # assign the column of data_sframe associated with the output to the SArray output_sarray\n",
    "    output_sarray=data_sframe[output]\n",
    "    # the following will convert the SArray into a numpy array by first converting it to a list\n",
    "    output_array = output_sarray.to_numpy()\n",
    "    return(feature_matrix, output_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7b1268c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_output(feature_matrix, weights):\n",
    "    # assume feature_matrix is a numpy matrix containing the features as columns and weights is a corresponding numpy array\n",
    "    # create the predictions vector by using np.dot()\n",
    "    predictions=np.dot(feature_matrix,weights)\n",
    "    return(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d76742e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_derivative(errors, feature):\n",
    "    # Assume that errors and feature are both numpy arrays of the same length (number of data points)\n",
    "    # compute twice the dot product of these vectors as 'derivative' and return the value\n",
    "    derivative=2*np.dot(errors, feature)\n",
    "    return(derivative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de074c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0ca27ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_gradient_descent(feature_matrix, output, initial_weights, step_size, tolerance):\n",
    "    converged = False \n",
    "    weights = np.array(initial_weights) # make sure it's a numpy array\n",
    "    while not converged:\n",
    "        # compute the predictions based on feature_matrix and weights using your predict_output() function\n",
    "        predictions=predict_output(feature_matrix, weights)\n",
    "        # compute the errors as predictions - output\n",
    "        errors=predictions-output\n",
    "        gradient_sum_squares = 0 # initialize the gradient sum of squares\n",
    "        # while we haven't reached the tolerance yet, update each feature's weight\n",
    "        for i in range(len(weights)): # loop over each weight\n",
    "            # Recall that feature_matrix[:, i] is the feature column associated with weights[i]\n",
    "            # compute the derivative for weight[i]:\n",
    "            derivative=feature_derivative(errors, feature_matrix[:,i])\n",
    "            # add the squared value of the derivative to the gradient sum of squares (for assessing convergence)\n",
    "            gradient_sum_squares+=(derivative**2)\n",
    "            # subtract the step size times the derivative from the current weight\n",
    "            weights[i]-=(step_size*derivative)\n",
    "        # compute the square-root of the gradient sum of squares to get the gradient magnitude:\n",
    "        gradient_magnitude = sqrt(gradient_sum_squares)\n",
    "        if gradient_magnitude < tolerance:\n",
    "            converged = True\n",
    "    return(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "152e55af",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data,test_data = sales.random_split(.8,seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad7886f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_features = ['sqft_living']\n",
    "my_output = 'price'\n",
    "(simple_feature_matrix, output) = get_numpy_data(train_data, simple_features, my_output)\n",
    "initial_weights = np.array([-47000., 1.])\n",
    "step_size = 7e-12\n",
    "tolerance = 2.5e7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a29de45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_weights = regression_gradient_descent(simple_feature_matrix, output, initial_weights, step_size, tolerance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "808a69e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-46999.88716555,    281.91211918])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b7872fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_features = ['sqft_living']\n",
    "my_output = 'price'\n",
    "(test_simple_feature_matrix, test_output) = get_numpy_data(test_data, simple_features, my_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3203f568",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions=predict_output(test_simple_feature_matrix, simple_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "49b3e60d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "356134.4432550024"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e16a4c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_res=test_output-test_predictions\n",
    "test_RSS= (test_res*test_res).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3f3547c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "275400044902128.3"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_RSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "89770b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_features = ['sqft_living', 'sqft_living15']\n",
    "my_output = 'price'\n",
    "(feature_matrix, output) = get_numpy_data(train_data, model_features,my_output)\n",
    "initial_weights = np.array([-100000., 1., 1.])\n",
    "step_size = 4e-12\n",
    "tolerance = 1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ab001ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_model_2=regression_gradient_descent(feature_matrix, output, initial_weights, step_size, tolerance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3d6e10f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "(test_feature_matrix, test_output) = get_numpy_data(test_data, model_features, my_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fcca7257",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions_2=predict_output(test_feature_matrix, weights_model_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "27cee8c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "366651.4116294939"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions_2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c78e7ea1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "310000.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "48a1fc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_res=test_output-test_predictions_2\n",
    "test_RSS= (test_res*test_res).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a2e53f65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "270263443629803.56"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_RSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fa026d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
